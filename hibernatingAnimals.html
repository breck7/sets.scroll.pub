<!DOCTYPE html>
<html lang="en">
<head>
 <meta charset="utf-8">
 <title>Animals that Hibernate</title>
 <script>/* This HTML was generated by üìú Scroll v158.0.4. https://scroll.pub */</script>
 <style>@media print {.doNotPrint {display: none !important;}}</style>
 <link rel="canonical" href="https://sets.scroll.pub/hibernatingAnimals.html">
 <meta name="viewport" content="width=device-width,initial-scale=1">
 <meta name="description" content="Concepts">
 <meta name="generator" content="Scroll v158.0.4">
 <meta property="og:title" content="Animals that Hibernate">
 <meta property="og:description" content="Concepts">
 <meta property="og:image" content="">
 
 <link rel="source" type="application/git" title="Source Code Repository" href="https://github.com/breck7/sets.scroll.pub">
 
 <meta name="twitter:card" content="summary_large_image">
</head>
<body>
<link rel="stylesheet" type="text/css" href="gazette.css"></link>

<style>.abstractIconButtonParser {position:absolute;top:0.25rem; }.abstractIconButtonParser svg {fill: rgba(204,204,204,.8);width:1.875rem;height:1.875rem; padding: 0 7px;} .abstractIconButtonParser:hover svg{fill: #333;}</style><a href="index.html" class="doNotPrint abstractIconButtonParser" style="left:2rem;"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.7166 3.79541C12.2835 3.49716 11.7165 3.49716 11.2834 3.79541L4.14336 8.7121C3.81027 8.94146 3.60747 9.31108 3.59247 9.70797C3.54064 11.0799 3.4857 13.4824 3.63658 15.1877C3.7504 16.4742 4.05336 18.1747 4.29944 19.4256C4.41371 20.0066 4.91937 20.4284 5.52037 20.4284H8.84433C8.98594 20.4284 9.10074 20.3111 9.10074 20.1665V15.9754C9.10074 14.9627 9.90433 14.1417 10.8956 14.1417H13.4091C14.4004 14.1417 15.204 14.9627 15.204 15.9754V20.1665C15.204 20.3111 15.3188 20.4284 15.4604 20.4284H18.4796C19.0806 20.4284 19.5863 20.0066 19.7006 19.4256C19.9466 18.1747 20.2496 16.4742 20.3634 15.1877C20.5143 13.4824 20.4594 11.0799 20.4075 9.70797C20.3925 9.31108 20.1897 8.94146 19.8566 8.7121L12.7166 3.79541ZM10.4235 2.49217C11.3764 1.83602 12.6236 1.83602 13.5765 2.49217L20.7165 7.40886C21.4457 7.91098 21.9104 8.73651 21.9448 9.64736C21.9966 11.0178 22.0564 13.5119 21.8956 15.3292C21.7738 16.7067 21.4561 18.4786 21.2089 19.7353C20.9461 21.0711 19.7924 22.0001 18.4796 22.0001H15.4604C14.4691 22.0001 13.6655 21.1791 13.6655 20.1665V15.9754C13.6655 15.8307 13.5507 15.7134 13.4091 15.7134H10.8956C10.754 15.7134 10.6392 15.8307 10.6392 15.9754V20.1665C10.6392 21.1791 9.83561 22.0001 8.84433 22.0001H5.52037C4.20761 22.0001 3.05389 21.0711 2.79113 19.7353C2.54392 18.4786 2.22624 16.7067 2.10437 15.3292C1.94358 13.5119 2.00338 11.0178 2.05515 9.64736C2.08957 8.73652 2.55427 7.91098 3.28346 7.40886L10.4235 2.49217Z"/></svg></a>
<style>a.keyboardNav {display:block;position:absolute;top:0.25rem; color: rgba(204,204,204,.8); font-size: 1.875rem; line-height: 1.7rem;}a.keyboardNav:hover{color: #333;text-decoration: none;}</style><a class="keyboardNav doNotPrint" style="left:.5rem;" href="physics2.html">&lt;</a><a class="keyboardNav doNotPrint" style="right:.5rem;" href="hormones.html">&gt;</a>
<style>.abstractIconButtonParser {position:absolute;top:0.25rem; }.abstractIconButtonParser svg {fill: rgba(204,204,204,.8);width:1.875rem;height:1.875rem; padding: 0 7px;} .abstractIconButtonParser:hover svg{fill: #333;}</style><a href="https://github.com/breck7/sets.scroll.pub/blob/main/hibernatingAnimals.scroll" class="doNotPrint abstractIconButtonParser" style="right:2rem;"><svg width="800px" height="800px" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M21.1213 2.70705C19.9497 1.53548 18.0503 1.53547 16.8787 2.70705L15.1989 4.38685L7.29289 12.2928C7.16473 12.421 7.07382 12.5816 7.02986 12.7574L6.02986 16.7574C5.94466 17.0982 6.04451 17.4587 6.29289 17.707C6.54127 17.9554 6.90176 18.0553 7.24254 17.9701L11.2425 16.9701C11.4184 16.9261 11.5789 16.8352 11.7071 16.707L19.5556 8.85857L21.2929 7.12126C22.4645 5.94969 22.4645 4.05019 21.2929 2.87862L21.1213 2.70705ZM18.2929 4.12126C18.6834 3.73074 19.3166 3.73074 19.7071 4.12126L19.8787 4.29283C20.2692 4.68336 20.2692 5.31653 19.8787 5.70705L18.8622 6.72357L17.3068 5.10738L18.2929 4.12126ZM15.8923 6.52185L17.4477 8.13804L10.4888 15.097L8.37437 15.6256L8.90296 13.5112L15.8923 6.52185ZM4 7.99994C4 7.44766 4.44772 6.99994 5 6.99994H10C10.5523 6.99994 11 6.55223 11 5.99994C11 5.44766 10.5523 4.99994 10 4.99994H5C3.34315 4.99994 2 6.34309 2 7.99994V18.9999C2 20.6568 3.34315 21.9999 5 21.9999H16C17.6569 21.9999 19 20.6568 19 18.9999V13.9999C19 13.4477 18.5523 12.9999 18 12.9999C17.4477 12.9999 17 13.4477 17 13.9999V18.9999C17 19.5522 16.5523 19.9999 16 19.9999H5C4.44772 19.9999 4 19.5522 4 18.9999V7.99994Z"/></svg></a>
<div class="scrollColumns" style="column-width:90ch;column-count:1;max-width:90ch;">
<div class="scrollSection"><h1 id="particle23" class="scrollTitle"><a href="hibernatingAnimals.html">Animals that Hibernate</a></h1>
</div>
<blockquote id="particle28" class="scrollQuote hideOnFront"><strong>What is a ScrollSet?</strong> <a href="https://breckyunits.com/scrollsets.html">Read the one page paper</a> | <a href="https://scroll.pub/blog/scrollsets.html">Tutorial</a> | <a href="https://scroll.pub/blog/csvToScrollSet.html">Convert a CSV to Scrollset</a></blockquote>
<blockquote id="particle30" class="scrollQuote hideOnFront">Note: these ScrollSets were generated by LLMs without extensive human review.</blockquote>
<div class="scrollSection"><h1 id="particle33" class="scrollParagraph">Concepts</h1>
</div>
</div>
<div class="scrollColumns" style="column-width:90ch;column-count:1;max-width:90ch;">
<table id="table9" class="scrollTable">
 <thead><tr><th>id</th>

<th>habitat</th>

<th>diet</th>

<th>averageHibernationDuration</th>

<th>bodyTemperatureDrop</th>

<th>heartRateReduction</th>

<th>breathingRateReduction</th>

<th>energySaved</th>
</tr></thead>
 <tbody><tr><td>Brown Bear</td>
<td>Forests</td>
<td>Omnivorous</td>
<td>180</td>
<td>10</td>
<td>20</td>
<td>5</td>
<td>50</td>
</tr>
<tr><td>Arctic Ground Squirrel</td>
<td>Tundra</td>
<td>Herbivorous</td>
<td>240</td>
<td>60</td>
<td>100</td>
<td>25</td>
<td>60</td>
</tr>
<tr><td>Common Poorwill</td>
<td>Deserts</td>
<td>Insectivorous</td>
<td>120</td>
<td>12</td>
<td>20</td>
<td>5</td>
<td>30</td>
</tr>
<tr><td>European Hedgehog</td>
<td>Woodlands</td>
<td>Insectivorous</td>
<td>150</td>
<td>40</td>
<td>50</td>
<td>10</td>
<td>70</td>
</tr>
<tr><td>Fat-tailed Dwarf Lemur</td>
<td>Tropical Forests</td>
<td>Frugivorous</td>
<td>180</td>
<td>15</td>
<td>15</td>
<td>5</td>
<td>40</td>
</tr>
<tr><td>Box Turtle</td>
<td>Forests and Grasslands</td>
<td>Omnivorous</td>
<td>150</td>
<td>20</td>
<td>10</td>
<td>2</td>
<td>50</td>
</tr>
<tr><td>Big Brown Bat</td>
<td>Caves and Forests</td>
<td>Insectivorous</td>
<td>180</td>
<td>30</td>
<td>100</td>
<td>20</td>
<td>80</td>
</tr>
<tr><td>Alpine Marmot</td>
<td>Mountains</td>
<td>Herbivorous</td>
<td>180</td>
<td>50</td>
<td>90</td>
<td>15</td>
<td>70</td>
</tr>
<tr><td>Raccoon</td>
<td>Forests and Urban Areas</td>
<td>Omnivorous</td>
<td>120</td>
<td>10</td>
<td>30</td>
<td>5</td>
<td>40</td>
</tr>
<tr><td>Eastern Chipmunk</td>
<td>Forests</td>
<td>Omnivorous</td>
<td>90</td>
<td>10</td>
<td>20</td>
<td>5</td>
<td>30</td>
</tr>
<tr><td>Wood Frog</td>
<td>Wetlands</td>
<td>Insectivorous</td>
<td>180</td>
<td>30</td>
<td>0</td>
<td>0</td>
<td>60</td>
</tr>
<tr><td>Snapping Turtle</td>
<td>Freshwater</td>
<td>Omnivorous</td>
<td>180</td>
<td>20</td>
<td>10</td>
<td>2</td>
<td>50</td>
</tr>
<tr><td>Blanding's Turtle</td>
<td>Freshwater</td>
<td>Omnivorous</td>
<td>150</td>
<td>20</td>
<td>10</td>
<td>2</td>
<td>50</td>
</tr>
<tr><td>Garter Snake</td>
<td>Grasslands</td>
<td>Carnivorous</td>
<td>180</td>
<td>10</td>
<td>10</td>
<td>5</td>
<td>40</td>
</tr>
<tr><td>Bumblebee</td>
<td>Gardens and Meadows</td>
<td>Nectar and Pollen</td>
<td>210</td>
<td>20</td>
<td>10</td>
<td>10</td>
<td>60</td>
</tr>
<tr><td>Groundhog</td>
<td>Fields and Forests</td>
<td>Herbivorous</td>
<td>150</td>
<td>40</td>
<td>50</td>
<td>10</td>
<td>70</td>
</tr>
<tr><td>Bear</td>
<td>Forests and Mountains</td>
<td>Omnivorous</td>
<td>120</td>
<td>12</td>
<td>10</td>
<td>5</td>
<td>50</td>
</tr>
<tr><td>Jerboa</td>
<td>Deserts</td>
<td>Herbivorous</td>
<td>180</td>
<td>15</td>
<td>20</td>
<td>5</td>
<td>40</td>
</tr>
<tr><td>Little Brown Bat</td>
<td>Caves and Forests</td>
<td>Insectivorous</td>
<td>180</td>
<td>30</td>
<td>100</td>
<td>20</td>
<td>80</td>
</tr>
<tr><td>Deer Mouse</td>
<td>Forests and Grasslands</td>
<td>Omnivorous</td>
<td>180</td>
<td>20</td>
<td>10</td>
<td>5</td>
<td>50</td>
</tr></tbody>
 </table>
</div>
<div class="dinkus"><span>‚ÅÇ</span></div>
<div class="scrollColumns" style="column-width:90ch;column-count:1;max-width:90ch;">
<script>
sendFormViaEmail = form => {
  const mailto = new URL("mailto:")
  const params = []
  const { value, title } = form.querySelector('button[type="submit"]')
  params.push(`subject=${encodeURIComponent(value)}`)
  params.push(`to=${encodeURIComponent(title)}`)
  const oneTextarea = form.querySelector('textarea[title="oneTextarea"]')
  const body = oneTextarea ? codeMirrorInstance.getValue() : Array.from(new FormData(form)).map(([name, value]) => `${name} ${value}`).join("\n")
  params.push(`body=${encodeURIComponent(body)}`)
  mailto.search = params.join("&")
  window.open(mailto.href, '_blank')
}
</script><style> .scrollFormParser {
    font-family: "Gill Sans", "Bitstream Vera Sans", sans-serif;
  }
.scrollFormParser input , .scrollFormParser textarea{
padding: 10px;
margin-bottom: 10px;
width: 100%;
box-sizing: border-box;
} .scrollFormParser label {
  display: block;
  margin-bottom: 5px;
}
</style><form onsubmit='sendFormViaEmail(this); return false;' class="scrollFormParser"><div><label for="id" title="Required">Id*:</label><input placeholder="What is the ID of this concept?" type="text" id="id" name="id" required></div>
<div><label for="habitat" title="">Habitat:</label><input placeholder="The typical habitat of the animal" type="text" id="habitat" name="habitat" ></div>
<div><label for="diet" title="">Diet:</label><input placeholder="The typical diet of the animal" type="text" id="diet" name="diet" ></div>
<div><label for="averageHibernationDuration" title="">AverageHibernationDuration:</label><input placeholder="The average duration of hibernation in days" type="number" id="averageHibernationDuration" name="averageHibernationDuration" ></div>
<div><label for="bodyTemperatureDrop" title="">BodyTemperatureDrop:</label><input placeholder="The average drop in body temperature during hibernation in degrees Fahrenheit" type="number" id="bodyTemperatureDrop" name="bodyTemperatureDrop" ></div>
<div><label for="heartRateReduction" title="">HeartRateReduction:</label><input placeholder="The average reduction in heart rate during hibernation in beats per minute (bpm)" type="number" id="heartRateReduction" name="heartRateReduction" ></div>
<div><label for="breathingRateReduction" title="">BreathingRateReduction:</label><input placeholder="The average reduction in breathing rate during hibernation in breaths per minute" type="number" id="breathingRateReduction" name="breathingRateReduction" ></div>
<div><label for="energySaved" title="">EnergySaved:</label><input placeholder="The percentage of energy saved during hibernation" type="number" id="energySaved" name="energySaved" ></div><button value="ScrollSets classic submission" title="breck7+setsclassic@gmail.com" class="scrollButton" type="submit">Submit via email</button></form>
<link rel="stylesheet" href="codeMirror.css">
<script src="scrollLibs.js"></script>

<script>
sendFormViaEmail = form => {
  const mailto = new URL("mailto:")
  const params = []
  const { value, title } = form.querySelector('button[type="submit"]')
  params.push(`subject=${encodeURIComponent(value)}`)
  params.push(`to=${encodeURIComponent(title)}`)
  const oneTextarea = form.querySelector('textarea[title="oneTextarea"]')
  const body = oneTextarea ? codeMirrorInstance.getValue() : Array.from(new FormData(form)).map(([name, value]) => `${name} ${value}`).join("\n")
  params.push(`body=${encodeURIComponent(body)}`)
  mailto.search = params.join("&")
  window.open(mailto.href, '_blank')
}
</script><style> .scrollFormParser {
    font-family: "Gill Sans", "Bitstream Vera Sans", sans-serif;
  }
.scrollFormParser input , .scrollFormParser textarea{
padding: 10px;
margin-bottom: 10px;
width: 100%;
box-sizing: border-box;
} .scrollFormParser label {
  display: block;
  margin-bottom: 5px;
}
</style><form onsubmit='sendFormViaEmail(this); return false;' class="scrollFormParser"><textarea title="oneTextarea" rows="16" placeholder="" id="particles" name="particles"></textarea>
  <script id="particlesParsers" type="text/plain">columnNameAtom
 extends stringAtom

percentAtom
 paint constant.numeric.float
 extends stringAtom
 // todo: this currently extends from stringAtom b/c scrollsdk needs to be fixed. seems like if extending from number then the hard coded number typescript regex takes precedence over a custom regex
countAtom
 extends integerAtom
yearAtom
 extends integerAtom

preBuildCommandAtom
 extends cueAtom
 description Give build command atoms their own color.
 paint constant.character.escape

delimiterAtom
 description String to use as a delimiter.
 paint string

bulletPointAtom
 description Any token used as a bullet point such as "-" or "1." or ">"
 paint keyword

comparisonAtom
 enum < > <= >= = != includes doesNotInclude empty notEmpty startsWith endsWith
 paint constant

personNameAtom
 extends stringAtom

// Link atom types
urlAtom
 paint constant.language
absoluteUrlAtom
 paint constant.language
 regex (ftp|https?)://.+

emailAddressAtom
 extends stringAtom

// File system atom types
permalinkAtom
 paint string
 description A string that doesn't contain characters that might interfere with most filesystems. No slashes, for instance.

filePathAtom
 extends stringAtom

// HTML atom types
tagOrUrlAtom
 description An HTML tag or a url.
 paint constant.language

htmlAttributesAtom
 paint comment

htmlTagAtom
 paint constant.language
 enum div span p a img ul ol li h1 h2 h3 h4 h5 h6 header nav section article aside main footer input button form label select option textarea table tr td th tbody thead tfoot br hr meta link script style title code

classNameAtom
 paint constant

htmlIdAtom
 extends anyAtom

fontFamilyAtom
 enum Arial Helvetica Verdana Georgia Impact Tahoma Slim
 paint constant

abstractScrollParser
 atoms cueAtom
 javascript
  buildHtmlSnippet(buildSettings) {
   return this.buildHtml(buildSettings)
  }
  buildTxt() {
    return ""
  }
  getHtmlRequirements(buildSettings) {
    const {requireOnce} = this
    if (!requireOnce)
      return ""
    const set = buildSettings?.alreadyRequired || this.root.alreadyRequired
    if (set.has(requireOnce))
      return ""
    
    set.add(requireOnce)
    return requireOnce + "\n\n"
  }

abstractScrollWithRequirementsParser
 extends abstractScrollParser
 cueFromId
 javascript
  buildHtml(buildSettings) {
    return this.getHtmlRequirements(buildSettings) + this.buildInstance()
  }

metaCommandAtom
 extends cueAtom
 description Give meta command atoms their own color.
 paint constant.numeric
 // Obviously this is not numeric. But I like the green color for now.
   We need a better design to replace this "paint" concept
   https://github.com/breck7/scrollsdk/issues/186

abstractTopLevelSingleMetaParser
 description Use these parsers once per file.
 extends abstractScrollParser
 inScope slashCommentParser
 cueFromId
 atoms metaCommandAtom
 javascript
  isTopMatter = true
  isSetterParser = true
  buildHtml() {
   return ""
  }

scrollParser
 description Scroll is a language for scientists of all ages. Refine, share and collaborate on ideas.
 root
 inScope abstractScrollParser blankLineParser atomTypeDefinitionParser parserDefinitionParser
 catchAllParser errorParser
 javascript
  setFile(file) {
   this.file = file
   return this
  }
  buildHtml(buildSettings) {
    this.sectionStack = []
    return this.filter(subparticle => subparticle.buildHtml).map(subparticle => { try {return subparticle.buildHtml(buildSettings)} catch (err) {console.error(err); return ""} }).filter(i => i).join("\n") + this.clearSectionStack()
  }
  sectionStack = []
  clearSectionStack() {
   const result = this.sectionStack.join("\n")
   this.sectionStack = []
   return result
  }
  bodyStack = []
  clearBodyStack() {
   const result = this.bodyStack.join("")
   this.bodyStack = []
   return result
  }
  get hakonParser() {
    if (this.isNodeJs())
      return require("scrollsdk/products/hakon.nodejs.js")
    return hakonParser
  }
  readSyncFromFileOrUrl(fileOrUrl) {
    if (!this.isNodeJs()) return localStorage.getItem(fileOrUrl) || ""
    const isUrl = fileOrUrl.match(/^https?\:[^ ]+$/)
    if (!isUrl) return this.root.readFile(fileOrUrl)
    return this.readFile(this.makeFullPath(new URL(fileOrUrl).pathname.split('/').pop()))
  }
  async fetch(url, filename) {
    const isUrl = url.match(/^https?\:[^ ]+$/)
    if (!isUrl) return
    return this.isNodeJs() ? this.fetchNode(url, filename) : this.fetchBrowser(url)
  }
  get path() {
    return require("path")
  }
  makeFullPath(filename) {
    return this.path.join(this.folderPath, filename)
  }
  _nextAndPrevious(arr, index) {
    const nextIndex = index + 1
    const previousIndex = index - 1
    return {
      previous: arr[previousIndex] ?? arr[arr.length - 1],
      next: arr[nextIndex] ?? arr[0]
    }
  }
  // keyboard nav is always in the same folder. does not currently support cross folder
  includeFileInKeyboardNav(file) {
    const { scrollProgram } = file
    return scrollProgram.buildsHtml && scrollProgram.hasKeyboardNav && scrollProgram.tags.includes(this.primaryTag)
  }
  get timeIndex() {
    return this.file.timeIndex || 0
  }
  get linkToPrevious() {
    if (!this.hasKeyboardNav)
      // Dont provide link to next unless keyboard nav is on
      return undefined
    const {allScrollFiles} = this
    let file = this._nextAndPrevious(allScrollFiles, this.timeIndex).previous
    while (!this.includeFileInKeyboardNav(file)) {
      file = this._nextAndPrevious(allScrollFiles, file.timeIndex).previous
    }
    return file.scrollProgram.permalink
  }
  get linkToNext() {
    if (!this.hasKeyboardNav)
      // Dont provide link to next unless keyboard nav is on
      return undefined
    const {allScrollFiles} = this
    let file = this._nextAndPrevious(allScrollFiles, this.timeIndex).next
    while (!this.includeFileInKeyboardNav(file)) {
      file = this._nextAndPrevious(allScrollFiles, file.timeIndex).next
    }
    return file.scrollProgram.permalink
  }
  // todo: clean up this naming pattern and add a parser instead of special casing 404.html
  get allHtmlFiles() {
    return this.allScrollFiles.filter(file => file.scrollProgram.buildsHtml && file.scrollProgram.permalink !== "404.html")
  }
  parseNestedTag(tag) {
    if (!tag.includes("/")) return;
    const {path} = this
    const parts = tag.split("/")
    const group = parts.pop()
    const relativePath = parts.join("/")
    return {
      group,
      relativePath,
      folderPath: path.join(this.folderPath, path.normalize(relativePath))
      }
  }
  getFilesByTags(tags, limit) {
    // todo: tags is currently matching partial substrings
    const getFilesWithTag = (tag, files) => files.filter(file => file.scrollProgram.buildsHtml && file.scrollProgram.tags.includes(tag))
    if (typeof tags === "string") tags = tags.split(" ")
    if (!tags || !tags.length)
      return this.allHtmlFiles
        .filter(file => file !== this) // avoid infinite loops. todo: think this through better.
        .map(file => {
          return { file, relativePath: "" }
        })
        .slice(0, limit)
    let arr = []
    tags.forEach(tag => {
      if (!tag.includes("/"))
        return (arr = arr.concat(
          getFilesWithTag(tag, this.allScrollFiles)
            .map(file => {
              return { file, relativePath: "" }
            })
            .slice(0, limit)
        ))
      const {folderPath, group, relativePath} = this.parseNestedTag(tag)
      let files = []
      try {
      files = this.fileSystem.getCachedLoadedFilesInFolder(folderPath, this)
      } catch (err) {
        console.error(err)
      }
      const filtered = getFilesWithTag(group, files).map(file => {
        return { file, relativePath: relativePath + "/" }
      })
      arr = arr.concat(filtered.slice(0, limit))
    })
    return this.lodash.sortBy(arr, file => file.file.timestamp).reverse()
  }
  async fetchNode(url, filename) {
    filename = filename || new URL(url).pathname.split('/').pop()
    const fullpath = this.makeFullPath(filename)
    if (require("fs").existsSync(fullpath)) return this.readFile(fullpath)
    this.log(`üõú fetching ${url} to ${fullpath} `)
    await this.downloadToDisk(url, fullpath)
    return this.readFile(fullpath)
  }
  log(message) {
    this.file.log ? this.file.log(message) : ""
  }
  async fetchBrowser(url) {
    const content = localStorage.getItem(url)
    if (content) return content
    return this.downloadToLocalStorage(url)
  }
  async downloadToDisk(url, destination) {
    const { writeFile } = require('fs').promises
    const response = await fetch(url)
    const fileBuffer = await response.arrayBuffer()
    await writeFile(destination, Buffer.from(fileBuffer))
    return this.readFile(destination)
  }
  async downloadToLocalStorage(url) {
    const response = await fetch(url)
    const blob = await response.blob()
    localStorage.setItem(url, await blob.text())
    return localStorage.getItem(url)
  }
  readFile(filename) {
    const {path} = this
    const fs = require("fs")
    const fullPath = path.join(this.folderPath, filename.replace(this.folderPath, ""))
    if (fs.existsSync(fullPath))
      return fs.readFileSync(fullPath, "utf8")
    console.error(`File '${filename}' not found`)
    return ""
  }
  alreadyRequired = new Set()
  buildHtmlSnippet(buildSettings) {
   this.sectionStack = []
   return this.map(subparticle => (subparticle.buildHtmlSnippet ? subparticle.buildHtmlSnippet(buildSettings) : subparticle.buildHtml(buildSettings)))
     .filter(i => i)
     .join("\n")
     .trim() + this.clearSectionStack()
  }
  get footnotes() {
   if (this._footnotes === undefined) this._footnotes = this.filter(particle => particle.isFootnote)
   return this._footnotes
  }
  get authors() {
    return this.get("authors")
  }
  get allScrollFiles() {
    try {
    return this.fileSystem.getCachedLoadedFilesInFolder(this.folderPath, this)
    } catch (err) {
      console.error(err)
      return []
    }
  }
  async doThing(thing) {
    await Promise.all(this.filter(particle => particle[thing]).map(async particle => particle[thing]()))
  }
  async load() {
    await this.doThing("load")
  }
  async execute() {
    await this.doThing("execute")
  }
  file = {}
  getFromParserId(parserId) {
    return this.parserIdIndex[parserId]?.[0].content
  }
  get fileSystem() {
    return this.file.fileSystem
  }
  get filePath() {
    return this.file.filePath
  }
  get folderPath() {
    return this.file.folderPath
  }
  get filename() {
    return this.file.filename || ""
  }
  get hasKeyboardNav() {
    return this.has("keyboardNav")
  }
  get editHtml() {
    return `<a href="${this.editUrl}" class="abstractTextLinkParser">Edit</a>`
  }
  get externalsPath() {
    return this.file.EXTERNALS_PATH
  }
  get endSnippetIndex() {
    // Get the line number that the snippet should stop at.
    // First if its hard coded, use that
    if (this.has("endSnippet")) return this.getParticle("endSnippet").index
    // Next look for a dinkus
    const snippetBreak = this.find(particle => particle.isDinkus)
    if (snippetBreak) return snippetBreak.index
    return -1
  }
  get parserIds() {
    return this.topDownArray.map(particle => particle.definition.id)
  }
  get tags() {
    return this.get("tags") || ""
  }
  get primaryTag() {
    return this.tags.split(" ")[0]
  }
  get filenameNoExtension() {
    return this.filename.replace(".scroll", "")
  }
  // todo: rename publishedUrl? Or something to indicate that this is only for stuff on the web (not localhost)
  // BaseUrl must be provided for RSS Feeds and OpenGraph tags to work
  get baseUrl() {
    const baseUrl = (this.get("baseUrl") || "").replace(/\/$/, "")
    return baseUrl + "/"
  }
  get canonicalUrl() {
    return this.get("canonicalUrl") || this.baseUrl + this.permalink
  }
  get openGraphImage() {
    const openGraphImage = this.get("openGraphImage")
    if (openGraphImage !== undefined) return this.ensureAbsoluteLink(openGraphImage)
    const images = this.filter(particle => particle.doesExtend("scrollImageParser"))
    const hit = images.find(particle => particle.has("openGraph")) || images[0]
    if (!hit) return ""
    return this.ensureAbsoluteLink(hit.filename)
  }
  get absoluteLink() {
    return this.ensureAbsoluteLink(this.permalink)
  }
  ensureAbsoluteLink(link) {
    if (link.includes("://")) return link
    return this.baseUrl + link.replace(/^\//, "")
  }
  get editUrl() {
    const editUrl = this.get("editUrl")
    if (editUrl) return editUrl
    const editBaseUrl = this.get("editBaseUrl")
    return (editBaseUrl ? editBaseUrl.replace(/\/$/, "") + "/" : "") + this.filename
  }
  get gitRepo() {
    // given https://github.com/breck7/breckyunits.com/blob/main/four-tips-to-improve-communication.scroll
    // return https://github.com/breck7/breckyunits.com
    return this.editUrl.split("/").slice(0, 5).join("/")
  }
  get scrollVersion() {
    return this.file.SCROLL_VERSION
  }
  // Use the first paragraph for the description
  // todo: add a particle method version of get that gets you the first particle. (actulaly make get return array?)
  // would speed up a lot.
  get description() {
    const description = this.getFromParserId("openGraphDescriptionParser")
    if (description) return description
    return this.generatedDescription
  }
  get generatedDescription() {
    const firstParagraph = this.find(particle => particle.isArticleContent)
    return firstParagraph ? firstParagraph.originalText.substr(0, 100).replace(/[&"<>']/g, "") : ""
  }
  get titleFromFilename() {
    const unCamelCase = str => str.replace(/([a-z])([A-Z])/g, "$1 $2").replace(/^./, match => match.toUpperCase())
    return unCamelCase(this.filenameNoExtension)
  }
  get title() {
    return this.getFromParserId("scrollTitleParser") || this.titleFromFilename
  }
  get linkTitle() {
    return this.getFromParserId("scrollLinkTitleParser") || this.title
  }
  get permalink() {
   return this.get("permalink") || (this.filename ? this.filenameNoExtension + ".html" : "")
  }
  compileTo(extensionCapitalized) {
    if (extensionCapitalized === "Txt")
      return this.asTxt
    if (extensionCapitalized === "Html")
      return this.asHtml
    const methodName = "build" + extensionCapitalized
    return this.topDownArray
      .filter(particle => particle[methodName])
      .map((particle, index) => particle[methodName](index))
      .join("\n")
      .trim()
  }
  get asTxt() {
    return (
      this.map(particle => {
          const text = particle.buildTxt ? particle.buildTxt() : ""
          if (text) return text + "\n"
          if (!particle.getLine().length) return "\n"
          return ""
        })
        .join("")
        .replace(/<[^>]*>/g, "")
        .replace(/\n\n\n+/g, "\n\n") // Maximum 2 newlines in a row
        .trim() + "\n" // Always end in a newline, Posix style
    )
  }
  get dependencies() {
      const dependencies = this.file.dependencies?.slice() || []
      const files = this.topDownArray.filter(particle => particle.dependencies).map(particle => particle.dependencies).flat()
      return dependencies.concat(files)
  }
  get buildsHtml() {
    const { permalink } = this
    return !this.file.importOnly && (permalink.endsWith(".html") || permalink.endsWith(".htm"))
  }
  // Without specifying the language hyphenation will not work.
  get lang() {
    return this.get("htmlLang") || "en"
  }
  _compiledHtml = ""
  get asHtml() {
    if (!this._compiledHtml) {
      const { permalink, buildsHtml } = this
      const content = (this.buildHtml() + this.clearBodyStack()).trim()
      // Don't add html tags to CSV feeds. A little hacky as calling a getter named _html_ to get _xml_ is not ideal. But
      // <1% of use case so might be good enough.
      const wrapWithHtmlTags = buildsHtml
      const bodyTag = this.has("metaTags") ? "" : "<body>\n"
      this._compiledHtml = wrapWithHtmlTags ? `<!DOCTYPE html>\n<html lang="${this.lang}">\n${bodyTag}${content}\n</body>\n</html>` : content
    }
    return this._compiledHtml
  }
  get wordCount() {
    return this.asTxt.match(/\b\w+\b/g)?.length || 0
  }
  get minutes() {
    return parseFloat((this.wordCount / 200).toFixed(1))
  }
  get date() {
    const date = this.get("date") || (this.file.timestamp ? this.file.timestamp : 0)
    return this.dayjs(date).format(`MM/DD/YYYY`)
  }
  get year() {
    return parseInt(this.dayjs(this.date).format(`YYYY`))
  }
  get dayjs() {
    if (!this.isNodeJs()) return dayjs
    const lib = require("dayjs")
    const relativeTime = require("dayjs/plugin/relativeTime")
    lib.extend(relativeTime)
    return lib
  }
  get lodash() {
    return this.isNodeJs() ? require("lodash") : lodash
  }
  getConcepts(parsed) {
    const concepts = []
    let currentConcept
    parsed.forEach(particle => {
      if (particle.isConceptDelimiter) {
        if (currentConcept) concepts.push(currentConcept)
        currentConcept = []
      }
      if (currentConcept && particle.isMeasure) currentConcept.push(particle)
    })
    if (currentConcept) concepts.push(currentConcept)
    return concepts
  }
  _formatConcepts(parsed) {
    const concepts = this.getConcepts(parsed)
    if (!concepts.length) return false
    const {lodash} = this
    // does a destructive sort in place on the parsed program
    concepts.forEach(concept => {
      let currentSection
      const newCode = lodash
        .sortBy(concept, ["sortIndex"])
        .map(particle => {
          let newLines = ""
          const section = particle.sortIndex.toString().split(".")[0]
          if (section !== currentSection) {
            currentSection = section
            newLines = "\n"
          }
          return newLines + particle.toString()
        })
        .join("\n")
      concept.forEach((particle, index) => (index ? particle.destroy() : ""))
      concept[0].replaceParticle(() => newCode)
    })
  }
  getFormatted(codeAtStart = this.toString()) {
    let formatted = codeAtStart.replace(/\r/g, "") // remove all carriage returns if there are any
    const parsed = new this.constructor(formatted)
    parsed.topDownArray.forEach(subparticle => {
      subparticle.format()
      const original = subparticle.getLine()
      const trimmed = original.replace(/(\S.*?)[  \t]*$/gm, "$1")
      // Trim trailing whitespace unless parser allows it
      if (original !== trimmed && !subparticle.allowTrailingWhitespace) subparticle.setLine(trimmed)
    })
    this._formatConcepts(parsed)
    let importOnlys = []
    let topMatter = []
    let allElse = []
    // Create any bindings
    parsed.forEach(particle => {
      if (particle.bindTo === "next") particle.binding = particle.next
      if (particle.bindTo === "previous") particle.binding = particle.previous
    })
    parsed.forEach(particle => {
      if (particle.getLine() === "importOnly") importOnlys.push(particle)
      else if (particle.isTopMatter) topMatter.push(particle)
      else allElse.push(particle)
    })
    const combined = importOnlys.concat(topMatter, allElse)
    // Move any bound particles
    combined
      .filter(particle => particle.bindTo)
      .forEach(particle => {
        // First remove the particle from its current position
        const originalIndex = combined.indexOf(particle)
        combined.splice(originalIndex, 1)
        // Then insert it at the new position
        // We need to find the binding index again after removal
        const bindingIndex = combined.indexOf(particle.binding)
        if (particle.bindTo === "next") combined.splice(bindingIndex, 0, particle)
        else combined.splice(bindingIndex + 1, 0, particle)
      })
    const trimmed = combined
      .map(particle => particle.toString())
      .join("\n")
      .replace(/^\n*/, "") // Remove leading newlines
      .replace(/\n\n\n+/g, "\n\n") // Maximum 2 newlines in a row
      .replace(/\n+$/, "")
    return trimmed === "" ? trimmed : trimmed + "\n" // End non blank Scroll files in a newline character POSIX style for better working with tools like git
  }
  get parser() {
    return this.constructor
  }
  get parsersRequiringExternals() {
    const { parser } = this
    // todo: could be cleaned up a bit
    if (!parser.parsersRequiringExternals) parser.parsersRequiringExternals = parser.cachedHandParsersProgramRoot.filter(particle => particle.copyFromExternal).map(particle => particle.atoms[0])
    return parser.parsersRequiringExternals
  }
  get Disk() { return this.isNodeJs() ? require("scrollsdk/products/Disk.node.js").Disk : {}}
  async buildAll() {
    await this.load()
    await this.buildOne()
    await this.buildTwo()
  }
  async buildOne() {
    await this.execute()
    const toBuild = this.filter(particle => particle.buildOne)
    for (let particle of toBuild) {
      await particle.buildOne()
    }
  }
  async buildTwo(externalFilesCopied = {}) {
    const toBuild = this.filter(particle => particle.buildTwo)
    for (let particle of toBuild) {
      await particle.buildTwo(externalFilesCopied)
    }
  }
  _compileArray(filename, arr) {
    const removeBlanks = data => data.map(obj => Object.fromEntries(Object.entries(obj).filter(([_, value]) => value !== "")))
    const parts = filename.split(".")
    const format = parts.pop()
    if (format === "json") return JSON.stringify(removeBlanks(arr), null, 2)
    if (format === "js") return `const ${parts[0]} = ` + JSON.stringify(removeBlanks(arr), null, 2)
    if (format === "csv") return this.arrayToCSV(arr)
    if (format === "tsv") return this.arrayToCSV(arr, "\t")
    if (format === "particles") return particles.toString()
    return particles.toString()
  }
  makeLodashOrderByParams(str) {
  const part1 = str.split(" ")
  const part2 = part1.map(col => (col.startsWith("-") ? "desc" : "asc"))
  return [part1.map(col => col.replace(/^\-/, "")), part2]
  }
  arrayToCSV(data, delimiter = ",") {
   if (!data.length) return ""
   // Extract headers
   const headers = Object.keys(data[0])
   const csv = data.map(row =>
     headers
       .map(fieldName => {
         const fieldValue = row[fieldName]
         // Escape commas if the value is a string
         if (typeof fieldValue === "string" && fieldValue.includes(delimiter)) {
           return `"${fieldValue.replace(/"/g, '""')}"` // Escape double quotes and wrap in double quotes
         }
         return fieldValue
       })
       .join(delimiter)
   )
   csv.unshift(headers.join(delimiter)) // Add header row at the top
   return csv.join("\n")
   }
  compileConcepts(filename = "csv", sortBy = "") {
    const {lodash} = this
    if (!sortBy) return this._compileArray(filename, this.concepts)
    const orderBy = this.makeLodashOrderByParams(sortBy)
    return this._compileArray(filename, lodash.orderBy(this.concepts, orderBy[0], orderBy[1]))
  }
  _withStats
  get measuresWithStats() {
    if (!this._withStats) this._withStats = this.addMeasureStats(this.concepts, this.measures)
    return this._withStats
  }
  addMeasureStats(concepts, measures){
   return measures.map(measure => {
    let Type = false
    concepts.forEach(concept => {
      const value = concept[measure.Name]
      if (value === undefined || value === "") return
      measure.Values++
      if (!Type) {
        measure.Example = value.toString().replace(/\n/g, " ")
        measure.Type = typeof value
        Type = true
      }
    })
    measure.Coverage = Math.floor((100 * measure.Values) / concepts.length) + "%"
    return measure
  })
  }
  parseMeasures(parser) {
  if (!Particle.measureCache)
    Particle.measureCache = new Map()
  const measureCache = Particle.measureCache
  if (measureCache.get(parser)) return measureCache.get(parser)
  const {lodash} = this
  // todo: clean this up
  const getCueAtoms = rootParserProgram =>
    rootParserProgram
      .filter(particle => particle.getLine().endsWith("Parser") && !particle.getLine().startsWith("abstract"))
      .map(particle => particle.get("cue") || particle.getLine())
      .map(line => line.replace(/Parser$/, ""))
  // Generate a fake program with one of every of the available parsers. Then parse it. Then we can easily access the meta data on the parsers
  const dummyProgram = new parser(
    Array.from(
      new Set(
        getCueAtoms(parser.cachedHandParsersProgramRoot) // is there a better method name than this?
      )
    ).join("\n")
  )
  // Delete any particles that are not measures
  dummyProgram.filter(particle => !particle.isMeasure).forEach(particle => particle.destroy())
  dummyProgram.forEach(particle => {
    // add nested measures
    Object.keys(particle.definition.cueMapWithDefinitions).forEach(key => particle.appendLine(key))
  })
  // Delete any nested particles that are not measures
  dummyProgram.topDownArray.filter(particle => !particle.isMeasure).forEach(particle => particle.destroy())
  const measures = dummyProgram.topDownArray.map(particle => {
    return {
      Name: particle.measureName,
      Values: 0,
      Coverage: 0,
      Question: particle.definition.description,
      Example: particle.definition.getParticle("example")?.subparticlesToString() || "",
      Type: particle.typeForWebForms,
      Source: particle.sourceDomain,
      //Definition: parsedProgram.root.filename + ":" + particle.lineNumber
      SortIndex: particle.sortIndex,
      IsComputed: particle.isComputed,
      IsRequired: particle.isMeasureRequired,
      IsConceptDelimiter: particle.isConceptDelimiter,
      Cue: particle.definition.get("cue")
    }
  })
  measureCache.set(parser, lodash.sortBy(measures, "SortIndex"))
  return measureCache.get(parser)
  }
  _concepts
  get concepts() {
    if (this._concepts) return this._concepts
    this._concepts = this.parseConcepts(this, this.measures)
    return this._concepts
  }
  _measures
  get measures() {
    if (this._measures) return this._measures
    this._measures = this.parseMeasures(this.parser)
    return this._measures
  }
  parseConcepts(parsedProgram, measures){
  // Todo: might be a perf/memory/simplicity win to have a "segment" method in ScrollSDK, where you could
  // virtually split a Particle into multiple segments, and then query on those segments.
  // So we would "segment" on "id ", and then not need to create a bunch of new objects, and the original
  // already parsed lines could then learn about/access to their respective segments.
  const conceptDelimiter = measures.filter(measure => measure.IsConceptDelimiter)[0]
  if (!conceptDelimiter) return []
  const concepts = parsedProgram.split(conceptDelimiter.Cue || conceptDelimiter.Name)
  concepts.shift() // Remove the part before "id"
  return concepts.map(concept => {
    const row = {}
    measures.forEach(measure => {
      const measureName = measure.Name
      const measureKey = measure.Cue || measureName.replace(/_/g, " ")
      if (!measure.IsComputed) row[measureName] = concept.getParticle(measureKey)?.measureValue ?? ""
      else row[measureName] = this.computeMeasure(parsedProgram, measureName, concept, concepts)
    })
    return row
  })
  }
  computeMeasure(parsedProgram, measureName, concept, concepts){
  // note that this is currently global, assuming there wont be. name conflicts in computed measures in a single scroll
  if (!Particle.measureFnCache) Particle.measureFnCache = {}
  const measureFnCache = Particle.measureFnCache
  if (!measureFnCache[measureName]) {
    // a bit hacky but works??
    const particle = parsedProgram.appendLine(measureName)
    measureFnCache[measureName] = particle.computeValue
    particle.destroy()
  }
  return measureFnCache[measureName](concept, measureName, parsedProgram, concepts)
  }
  compileMeasures(filename = "csv", sortBy = "") {
    const withStats = this.measuresWithStats
    if (!sortBy) return this._compileArray(filename, withStats)
    const orderBy = this.makeLodashOrderByParams(sortBy)
    return this._compileArray(filename, this.lodash.orderBy(withStats, orderBy[0], orderBy[1]))
  }
  evalNodeJsMacros(value, macroMap, filePath) {
    const tempPath = filePath + ".js"
    const {Disk} = this
    if (Disk.exists(tempPath)) throw new Error(`Failed to write/require replaceNodejs snippet since '${tempPath}' already exists.`)
    try {
      Disk.write(tempPath, value)
      const results = require(tempPath)
      Object.keys(results).forEach(key => (macroMap[key] = results[key]))
    } catch (err) {
      console.error(`Error in evalMacros in file '${filePath}'`)
      console.error(err)
    } finally {
      Disk.rm(tempPath)
    }
  }
  parseAndCompile(fusedCode, codeAtStart, absoluteFilePath, parser){
    // PASS 3: READ AND REPLACE MACROS. PARSE AND REMOVE MACROS DEFINITIONS THEN REPLACE REFERENCES.
    const codeAfterMacroPass = this.evalMacros(fusedCode, codeAtStart, absoluteFilePath)
    // PASS 4: READ WITH STD COMPILER OR CUSTOM COMPILER.
    return {
      codeAfterMacroPass,
      parser,
      scrollProgram: new parser(codeAfterMacroPass)
    }
  }
  evalMacros(code, codeAtStart, absolutePath) {
    // note: the 2 params above are not used in this method, but may be used in user eval code. (todo: cleanup)
    const regex = /^(replace|footer$)/gm
    if (!regex.test(code)) return code
    const particle = new Particle(code) // todo: this can be faster. a more lightweight particle class?
    // Process macros
    const macroMap = {}
    particle
      .filter(particle => {
        const parserAtom = particle.cue
        return parserAtom === "replace" || parserAtom === "replaceJs" || parserAtom === "replaceNodejs"
      })
      .forEach(particle => {
        let value = particle.length ? particle.subparticlesToString() : particle.getAtomsFrom(2).join(" ")
        const kind = particle.cue
        if (kind === "replaceJs") value = eval(value)
        if (this.isNodeJs() && kind === "replaceNodejs")
          this.evalNodeJsMacros(value, macroMap, absolutePath)
        else macroMap[particle.getAtom(1)] = value
        particle.destroy() // Destroy definitions after eval
      })
    if (particle.has("footer")) {
      const pushes = particle.getParticles("footer")
      const append = pushes.map(push => push.section.join("\n")).join("\n")
      pushes.forEach(push => {
        push.section.forEach(particle => particle.destroy())
        push.destroy()
      })
      code = particle.asString + append
    }
    const keys = Object.keys(macroMap)
    if (!keys.length) return code
    let codeAfterMacroSubstitution = particle.asString
    // Todo: speed up. build a template?
    Object.keys(macroMap).forEach(key => (codeAfterMacroSubstitution = codeAfterMacroSubstitution.replace(new RegExp(key, "g"), macroMap[key])))
    return codeAfterMacroSubstitution
  }
  toRss() {
    const { title, canonicalUrl } = this
    return ` <item>
  <title>${title}</title>
  <link>${canonicalUrl}</link>
  <pubDate>${this.dayjs(this.timestamp * 1000).format("ddd, DD MMM YYYY HH:mm:ss ZZ")}</pubDate>
  </item>`
  }
 example
  # Hello world
  ## This is Scroll
  * It compiles to HTML.
  
  code
   // You can add code as well.
   print("Hello world")

abstractUrlSettingParser
 extends abstractTopLevelSingleMetaParser
 atoms metaCommandAtom urlAtom
 cueFromId


buildCommandAtom
 extends cueAtom
 description Give build command atoms their own color.
 paint constant

abstractBuildCommandParser
 extends abstractScrollParser
 cueFromId
 atoms buildCommandAtom
 catchAllAtomType filePathAtom
 inScope slashCommentParser
 javascript
  isTopMatter = true
  buildHtml() {
   return ""
  }
  get extension() {
    return this.cue.replace("build", "")
  }
  buildOutput() {
    return this.root.compileTo(this.extension)
  }
  async _buildFileType(extension) {
    const {root} = this
    const { fileSystem, folderPath, filename, filePath, path, lodash, permalink } = root
    const capitalized = lodash.capitalize(extension)
    const buildKeyword = "build" + capitalized
    const outputFiles = this.content?.split(" ") || [""]
    for (let name of outputFiles) {
      const link = name || permalink.replace(".html", "." + extension.toLowerCase())
      try {
        await fileSystem.writeProduct(path.join(folderPath, link), root.compileTo(capitalized))
        root.log(`üíæ Built ${link} from ${filename}`)
      } catch (err) {
        console.error(`Error while building '${filePath}' with extension '${extension}'`)
        throw err
      }
    }
  }

abstractBuildOneCommandParser
 // buildOne and buildTwo are just a dumb/temporary way to have CSVs/JSONs/TSVs build first. Will be merged at some point.
 extends abstractBuildCommandParser
 javascript
  async buildOne() { await this._buildFileType(this.extension) }

abstractBuildTwoCommandParser
 extends abstractBuildCommandParser
 javascript
  async buildTwo() {
    await this._buildFileType(this.extension)
  }

commentLineParser
 catchAllAtomType commentAtom

abstractCommentParser
 description Prints nothing.
 catchAllAtomType commentAtom
 atoms commentAtom
 extends abstractScrollParser
 baseParser blobParser
 string bindTo next
 javascript
  buildHtml() {
   return ``
  }
 catchAllParser commentLineParser

commentParser
 popularity 0.000193
 extends abstractCommentParser
 cueFromId
 boolean suggestInAutocomplete false

slashCommentParser
 popularity 0.005643
 extends abstractCommentParser
 cue //
 boolean isPopular true
 description A comment. Prints nothing.
 boolean suggestInAutocomplete false

blankLineParser
 popularity 0.308149
 description Print nothing. Break section.
 atoms blankAtom
 boolean isPopular true
 javascript
  buildHtml() {
   return this.parent.clearSectionStack()
  }
 pattern ^$
 tags doNotSynthesize

measureNameAtom
 extends cueAtom
 // A regex for column names for max compatibility with a broad range of data science tools:
 regex [a-zA-Z][a-zA-Z0-9]*

buildMeasuresParser
 popularity 0.000024
 cueFromId
 description Write measures to csv+ files.
 extends abstractBuildCommandParser
 sortByParser
  cueFromId
  atoms cueAtom anyAtom
 javascript
  async buildOne() {
    const {root} = this
    const { fileSystem, folderPath, filename, path, permalink } = root
    const files = this.getAtomsFrom(1)
    if (!files.length) files.push(permalink.replace(".html", ".csv"))
    const sortBy = this.get("sortBy")
    for (let link of files) {
      await fileSystem.writeProduct(path.join(folderPath, link), root.compileMeasures(link, sortBy))
      root.log(`üíæ Built measures in ${filename} to ${link}`)
    }
  }
 boolean suggestInAutocomplete false

// The main measure parser. All measures should extend from this.
abstractMeasureParser
 atoms measureNameAtom
 cueFromId
 boolean isMeasure true
 float sortIndex 1.9
 boolean isComputed false
 string typeForWebForms text
 extends abstractScrollParser
 javascript
  buildHtmlSnippet() {
   return ""
  }
  buildHtml() {
   return ""
  }
  get measureValue() {
    return this.content ?? ""
  }
  get measureName() {
    return this.getCuePath().replace(/ /g, "_")
  }

// String Measures
abstractAtomMeasureParser
 description A measure that contains a single atom.
 atoms measureNameAtom atomAtom
 extends abstractMeasureParser

abstractStringMeasureParser
 catchAllAtomType stringAtom
 extends abstractMeasureParser

abstractTextareaMeasureParser
 string typeForWebForms textarea
 extends abstractMeasureParser
 baseParser blobParser
 javascript
  get measureValue() {
    return this.subparticlesToString().replace(/\n/g, "\\n")
  }

abstractEmailMeasureParser
 string typeForWebForms email
 atoms measureNameAtom emailAddressAtom
 extends abstractAtomMeasureParser

// URL Parsers
abstractUrlMeasureParser
 string typeForWebForms url
 atoms measureNameAtom urlAtom
 extends abstractAtomMeasureParser

// Required ID measure which denotes a concept
abstractIdParser
 cue id
 description What is the ID of this concept?
 extends abstractStringMeasureParser
 float sortIndex 1
 boolean isMeasureRequired true
 boolean isConceptDelimiter true
 javascript
  getErrors() {
    const errors = super.getErrors()
    let requiredMeasureNames = this.root.measures.filter(measure => measure.isMeasureRequired).map(measure => measure.Name).filter(name => name !== "id")
    if (!requiredMeasureNames.length) return errors
    let next = this.next
    while (requiredMeasureNames.length && next.cue !== "id" && next.index !== 0) {
      requiredMeasureNames = requiredMeasureNames.filter(i => i !== next.cue)
      next = next.next
    }
    requiredMeasureNames.forEach(name =>
      errors.push(this.makeError(`Concept "${this.content}" is missing required measure "${name}".`))
    )
    return errors
  }

// Numeric Measures
abstractNumericMeasureParser
 string typeForWebForms number
 extends abstractMeasureParser
 javascript
  get measureValue() {
    const {content} = this
    return content === undefined ? "" : parseFloat(content)
  }

abstractIntegerMeasureParser
 atoms measureNameAtom integerAtom
 extends abstractNumericMeasureParser

abstractFloatMeasureParser
 atoms measureNameAtom floatAtom
 extends abstractNumericMeasureParser

abstractPercentageMeasureParser
 atoms measureNameAtom percentAtom
 extends abstractNumericMeasureParser
 javascript
  get measureValue() {
    const {content} = this
    return content === undefined ? "" : parseFloat(content)
  }

// Enum Measures
abstractEnumMeasureParser
 atoms measureNameAtom enumAtom
 extends abstractMeasureParser

// Boolean Measures
abstractBooleanMeasureParser
 atoms measureNameAtom booleanAtom
 extends abstractMeasureParser
 javascript
  get measureValue() {
    const {content} = this
    return content === undefined ? "" : content == "true"
  }


errorParser
 baseParser errorParserdate 05/29/2024
title Animals that Hibernate

imported /home/runner/work/sets.scroll.pub/sets.scroll.pub/setHeader.scroll
 exists true
tags All ScrollSetDemos

imported /home/runner/work/sets.scroll.pub/sets.scroll.pub/header.scroll
 exists true
imported /home/runner/work/sets.scroll.pub/sets.scroll.pub/settings.scroll
 exists true
baseUrl https://sets.scroll.pub/
email feedback@scroll.pub
editBaseUrl https://github.com/breck7/sets.scroll.pub/blob/main


metaTags
stumpNoSnippet
 link
  rel stylesheet
  type text/css
  href gazette.css
homeButton
leftRightButtons
editButton


wideColumns 1
printTitle

imported /home/runner/work/sets.scroll.pub/sets.scroll.pub/disclaimer.scroll
 exists true

> *What is a ScrollSet?* Read the one page paper | Tutorial | Convert a CSV to Scrollset
 https://breckyunits.com/scrollsets.html Read the one page paper
 https://scroll.pub/blog/scrollsets.html Tutorial
 https://scroll.pub/blog/csvToScrollSet.html Convert a CSV to Scrollset
 classes scrollQuote hideOnFront

> Note: these ScrollSets were generated by LLMs without extensive human review.
 classes scrollQuote hideOnFront


# Concepts

endColumns

wideColumns 1
table
 printTable

endColumns

****

wideColumn
classicForm breck7+setsclassic@gmail.com ScrollSets classic submission
scrollForm breck7+sets@gmail.com ScrollSets advanced submission



Source: https://chatgpt.com/share/f3b49ff7-e9f5-41d0-9f23-ccc89214d995

idParser
 extends abstractIdParser

averageHibernationDurationParser
 extends abstractIntegerMeasureParser
 description The average duration of hibernation in days

bodyTemperatureDropParser
 extends abstractIntegerMeasureParser
 description The average drop in body temperature during hibernation in degrees Fahrenheit

heartRateReductionParser
 extends abstractIntegerMeasureParser
 description The average reduction in heart rate during hibernation in beats per minute (bpm)

breathingRateReductionParser
 extends abstractIntegerMeasureParser
 description The average reduction in breathing rate during hibernation in breaths per minute

energySavedParser
 extends abstractIntegerMeasureParser
 description The percentage of energy saved during hibernation

habitatParser
 extends abstractStringMeasureParser
 description The typical habitat of the animal

dietParser
 extends abstractStringMeasureParser
 description The typical diet of the animal

id Brown Bear
averageHibernationDuration 180
bodyTemperatureDrop 10
heartRateReduction 20
breathingRateReduction 5
energySaved 50
habitat Forests
diet Omnivorous

id Arctic Ground Squirrel
averageHibernationDuration 240
bodyTemperatureDrop 60
heartRateReduction 100
breathingRateReduction 25
energySaved 60
habitat Tundra
diet Herbivorous

id Common Poorwill
averageHibernationDuration 120
bodyTemperatureDrop 12
heartRateReduction 20
breathingRateReduction 5
energySaved 30
habitat Deserts
diet Insectivorous

id European Hedgehog
averageHibernationDuration 150
bodyTemperatureDrop 40
heartRateReduction 50
breathingRateReduction 10
energySaved 70
habitat Woodlands
diet Insectivorous

id Fat-tailed Dwarf Lemur
averageHibernationDuration 180
bodyTemperatureDrop 15
heartRateReduction 15
breathingRateReduction 5
energySaved 40
habitat Tropical Forests
diet Frugivorous

id Box Turtle
averageHibernationDuration 150
bodyTemperatureDrop 20
heartRateReduction 10
breathingRateReduction 2
energySaved 50
habitat Forests and Grasslands
diet Omnivorous

id Big Brown Bat
averageHibernationDuration 180
bodyTemperatureDrop 30
heartRateReduction 100
breathingRateReduction 20
energySaved 80
habitat Caves and Forests
diet Insectivorous

id Alpine Marmot
averageHibernationDuration 180
bodyTemperatureDrop 50
heartRateReduction 90
breathingRateReduction 15
energySaved 70
habitat Mountains
diet Herbivorous

id Raccoon
averageHibernationDuration 120
bodyTemperatureDrop 10
heartRateReduction 30
breathingRateReduction 5
energySaved 40
habitat Forests and Urban Areas
diet Omnivorous

id Eastern Chipmunk
averageHibernationDuration 90
bodyTemperatureDrop 10
heartRateReduction 20
breathingRateReduction 5
energySaved 30
habitat Forests
diet Omnivorous

id Wood Frog
averageHibernationDuration 180
bodyTemperatureDrop 30
heartRateReduction 0
breathingRateReduction 0
energySaved 60
habitat Wetlands
diet Insectivorous

id Snapping Turtle
averageHibernationDuration 180
bodyTemperatureDrop 20
heartRateReduction 10
breathingRateReduction 2
energySaved 50
habitat Freshwater
diet Omnivorous

id Blanding's Turtle
averageHibernationDuration 150
bodyTemperatureDrop 20
heartRateReduction 10
breathingRateReduction 2
energySaved 50
habitat Freshwater
diet Omnivorous

id Garter Snake
averageHibernationDuration 180
bodyTemperatureDrop 10
heartRateReduction 10
breathingRateReduction 5
energySaved 40
habitat Grasslands
diet Carnivorous

id Bumblebee
averageHibernationDuration 210
bodyTemperatureDrop 20
heartRateReduction 10
breathingRateReduction 10
energySaved 60
habitat Gardens and Meadows
diet Nectar and Pollen

id Groundhog
averageHibernationDuration 150
bodyTemperatureDrop 40
heartRateReduction 50
breathingRateReduction 10
energySaved 70
habitat Fields and Forests
diet Herbivorous

id Bear
averageHibernationDuration 120
bodyTemperatureDrop 12
heartRateReduction 10
breathingRateReduction 5
energySaved 50
habitat Forests and Mountains
diet Omnivorous

id Jerboa
averageHibernationDuration 180
bodyTemperatureDrop 15
heartRateReduction 20
breathingRateReduction 5
energySaved 40
habitat Deserts
diet Herbivorous

id Little Brown Bat
averageHibernationDuration 180
bodyTemperatureDrop 30
heartRateReduction 100
breathingRateReduction 20
energySaved 80
habitat Caves and Forests
diet Insectivorous

id Deer Mouse
averageHibernationDuration 180
bodyTemperatureDrop 20
heartRateReduction 10
breathingRateReduction 5
energySaved 50
habitat Forests and Grasslands
diet Omnivorous

imported /home/runner/work/sets.scroll.pub/sets.scroll.pub/pageFooter.scroll
 exists true
buildConcepts
buildTxt
buildHtml

tableSearch

keyboardNav

imported /home/runner/work/sets.scroll.pub/sets.scroll.pub/footer.scroll
 exists true

center
editButton
scrollVersionLink


</script>
  <script>{
  let {width, height} = document.getElementById('particles').getBoundingClientRect();
  const scrollParser = new HandParsersProgram(document.getElementById("particlesParsers").textContent).compileAndReturnRootParser()
  codeMirrorInstance = new ParsersCodeMirrorMode("custom", () => scrollParser, undefined, CodeMirror).register().fromTextAreaWithAutocomplete(document.getElementById("particles"), {
    lineWrapping: false,
    lineNumbers: false
  })
  codeMirrorInstance.setSize(width, height);
  codeMirrorInstance.setValue(``); }</script><button value="ScrollSets advanced submission" title="breck7+sets@gmail.com" class="scrollButton" type="submit">Submit via email</button></form>
</div>
<p id="particle50" class="scrollParagraph">Source: <a href="https://chatgpt.com/share/f3b49ff7-e9f5-41d0-9f23-ccc89214d995" target="_blank">https://chatgpt.com/share/f3b49ff7-e9f5-41d0-9f23-ccc89214d995</a></p>
<script defer src="jquery-3.7.1.min.js"></script>
<style>.dt-search{font-family: "SF Pro", "Helvetica Neue", "Segoe UI", "Arial";}</style>
<link rel="stylesheet" href="datatables.css">
<script defer src="datatables.js"></script>
<script defer src="dayjs.min.js"></script>
<script defer src="tableSearch.js"></script>


<div class="scrollKeyboardNav" style="display:none;"><a href="physics2.html">physics2.html</a> ¬∑ hibernatingAnimals.html ¬∑ <a href="hormones.html">hormones.html</a><script>document.addEventListener('keydown', function(event) {
  if (document.activeElement !== document.body) return
  if (event.altKey || event.ctrlKey || event.metaKey || event.shiftKey) return // dont interfere with keyboard back button shortcut
  const getLinks = () => document.getElementsByClassName("scrollKeyboardNav")[0].getElementsByTagName("a")
  if (event.key === "ArrowLeft")
    getLinks()[0].click()
  else if (event.key === "ArrowRight")
    getLinks()[1].click()
 });</script></div>
<center><p id="particle261" class="scrollParagraph"></p>
<style>.abstractIconButtonParser {position:absolute;top:0.25rem; }.abstractIconButtonParser svg {fill: rgba(204,204,204,.8);width:1.875rem;height:1.875rem; padding: 0 7px;} .abstractIconButtonParser:hover svg{fill: #333;}</style><a href="https://github.com/breck7/sets.scroll.pub/blob/main/hibernatingAnimals.scroll" class="doNotPrint abstractIconButtonParser" style="position:relative;"><svg width="800px" height="800px" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M21.1213 2.70705C19.9497 1.53548 18.0503 1.53547 16.8787 2.70705L15.1989 4.38685L7.29289 12.2928C7.16473 12.421 7.07382 12.5816 7.02986 12.7574L6.02986 16.7574C5.94466 17.0982 6.04451 17.4587 6.29289 17.707C6.54127 17.9554 6.90176 18.0553 7.24254 17.9701L11.2425 16.9701C11.4184 16.9261 11.5789 16.8352 11.7071 16.707L19.5556 8.85857L21.2929 7.12126C22.4645 5.94969 22.4645 4.05019 21.2929 2.87862L21.1213 2.70705ZM18.2929 4.12126C18.6834 3.73074 19.3166 3.73074 19.7071 4.12126L19.8787 4.29283C20.2692 4.68336 20.2692 5.31653 19.8787 5.70705L18.8622 6.72357L17.3068 5.10738L18.2929 4.12126ZM15.8923 6.52185L17.4477 8.13804L10.4888 15.097L8.37437 15.6256L8.90296 13.5112L15.8923 6.52185ZM4 7.99994C4 7.44766 4.44772 6.99994 5 6.99994H10C10.5523 6.99994 11 6.55223 11 5.99994C11 5.44766 10.5523 4.99994 10 4.99994H5C3.34315 4.99994 2 6.34309 2 7.99994V18.9999C2 20.6568 3.34315 21.9999 5 21.9999H16C17.6569 21.9999 19 20.6568 19 18.9999V13.9999C19 13.4477 18.5523 12.9999 18 12.9999C17.4477 12.9999 17 13.4477 17 13.9999V18.9999C17 19.5522 16.5523 19.9999 16 19.9999H5C4.44772 19.9999 4 19.5522 4 18.9999V7.99994Z"/></svg></a>
<div class="abstractTextLinkParser"><a href="https://scroll.pub">Built with Scroll v158.0.4</a></div>
</center>
</body>
</html>